knitr::opts_chunk$set(echo = TRUE)
# Carregar o conjunto de dados mtcars
data(mtcars)
# Verificar as primeiras linhas do conjunto de dados
head(mtcars)
# Verificar a estrutura do conjunto de dados
str(mtcars)
# Criar o modelo de regressão logística
modelo <- glm(am ~ hp + wt, data = mtcars, family = binomial)
# Sumário do modelo
summary(modelo)
View(mtcars)
# Importar a biblioteca necessária para ajustar o modelo de regressão logística
library(glmnet)
# Criar o modelo de regressão logística
modelo <- glm(am ~ hp + wt, data = mtcars, family = "binomial")
# Visualizar o resumo do modelo
summary(modelo)
# Fazer previsões com o modelo
predictions <- predict(modelo_logistico, newdata = mtcars, type = "response")
View(modelo)
# Criar o modelo de regressão logística
Error: object 'modelo_logistico' not found <- glm(am ~ hp + wt, data = mtcars, family = "binomial")
# Criar o modelo de regressão logística
modelo_logistico <- glm(am ~ hp + wt, data = mtcars, family = "binomial")
# Visualizar o resumo do modelo
summary(modelo)
# Fazer previsões com o modelo
predictions <- predict(modelo_logistico, newdata = mtcars, type = "response")
# Converter as probabilidades em classes (0 ou 1) usando um limite de 0.5
predicted_classes <- ifelse(predictions > 0.5, 1, 0)
# Comparar as previsões com os valores reais da variável am
num_acertos <- sum(predicted_classes == mtcars$am)
num_erros <- length(mtcars$am) - num_acertos
# Calcular o percentual de acerto
percentual_acerto <- (num_acertos / length(mtcars$am)) * 100
# Exibir os resultados
cat("Número de veículos classificados corretamente:", num_acertos, "\n")
cat("Número de veículos classificados erroneamente:", num_erros, "\n")
cat("Percentual de acerto:", percentual_acerto, "%\n")
# Carregando a biblioteca e visualizando as primeiras linhas do conjunto de dados
library(MASS)
head(Cars93)
# Verificando se há dados ausentes
sum(is.na(Cars93))
# Convertendo a variável de origem para numérica
Cars93$Origin <- ifelse(Cars93$Origin == "USA", 1, 0)
# Criando o modelo de regressão logística
modelo_logistico <- glm(Origin ~ Price + Weight + Length, family = "binomial", data = Cars93)
# Sumário do modelo
summary(modelo_logistico)
# Verificar se há dados ausentes
sum(is.na(Cars93))
# Converter o atributo "Origin" para numérico (1 e 0)
Cars93$Origin <- ifelse(Cars93$Origin == "non-USA", 0, 1)
# Criar o modelo de regressão logística
modelo_logistico <- glm(Origin ~ Price + Weight + Length, family = "binomial", data = Cars93)
# Visualizar os resultados
summary(modelo_logistico)
# Verificar se há dados ausentes
sum(is.na(Cars93))
# Converter o atributo "Origin" para numérico (1 e 0)
Cars93$Origin <- ifelse(Cars93$Origin == "non-USA", 0, 1)
# Criar o modelo de regressão logística
modelo_logistico <- glm(Origin ~ Price + Weight + Length, family = "binomial", data = Cars93)
# Visualizar os resultados
summary(modelo_logistico)
# Identificar atributo com coeficiente com pouca significância
coeficientes <- summary(modelo_logistico)$coefficients
p_valores <- coeficientes[, 4]
atributo_nao_significativo <- names(which(p_valores > 0.05))
cat("Atributo com coeficiente com pouca significância:", atributo_nao_significativo, "\n")
# Visualizar os coeficientes e os p-valores
coeficientes <- summary(modelo_logistico)$coefficients
coeficientes
# Remover o atributo com o menor p-valor (maior que 0.05)
atributo_remover <- which.min(coeficientes[,4])
atributo_remover_nome <- rownames(coeficientes)[atributo_remover]
Cars93_sem_atributo <- Cars93[, -which(names(Cars93) == atributo_remover_nome)]
# Refazer o modelo sem o atributo removido
modelo_logistico_sem_atributo <- glm(Origin ~ Price + Weight, family = "binomial", data = Cars93_sem_atributo)
# Visualizar os coeficientes e os p-valores
coeficientes <- summary(modelo_logistico)$coefficients
coeficientes
# Remover o atributo com o menor p-valor (maior que 0.05)
atributo_remover <- which.min(coeficientes[,4])
atributo_remover_nome <- rownames(coeficientes)[atributo_remover]
Cars93_sem_atributo <- Cars93[, -which(names(Cars93) == atributo_remover_nome)]
# Refazer o modelo sem o atributo removido
modelo_logistico_sem_atributo <- glm(Origin ~ Price + Length, family = "binomial", data = Cars93_sem_atributo)
# Remover o atributo com pouca significância
Cars93_sem_weight <- Cars93[, !colnames(Cars93) %in% c("Weight")]
# Refazer o modelo sem o atributo "Weight"
modelo_logistico_sem_weight <- glm(Origin ~ Price + Length, family = "binomial", data = Cars93_sem_weight)
# Visualizar os resultados do novo modelo
summary(modelo_logistico_sem_weight)
# Remover o atributo com pouca significância
Cars93_sem_weight <- Cars93[, !colnames(Cars93) %in% c("Weight")]
# Refazer o modelo sem o atributo "Weight"
modelo_logistico_sem_weight <- glm(Origin ~ Price + Length, family = "binomial", data = Cars93_sem_weight)
# Visualizar os resultados do novo modelo
summary(modelo_logistico_sem_weight)
# Identificar o atributo com menor p-valor
atributo_menor_pvalor <- names(coef(summary(modelo_logistico_sem_weight)))[which.min(coef(summary(modelo_logistico_sem_weight))[, 4])]
print("O atributo com menor p-valor é:")
print(atributo_menor_pvalor)
# Remover o atributo com pouca significância
Cars93_sem_weight <- Cars93[, !colnames(Cars93) %in% c("Weight")]
# Refazer o modelo sem o atributo "Weight"
modelo_logistico_sem_weight <- glm(Origin ~ Price + Length, family = "binomial", data = Cars93_sem_weight)
# Visualizar os resultados do novo modelo
summary(modelo_logistico_sem_weigh
t)
# Remover o atributo com pouca significância
Cars93_sem_weight <- Cars93[, !colnames(Cars93) %in% c("Weight")]
# Refazer o modelo sem o atributo "Weight"
modelo_logistico_sem_weight <- glm(Origin ~ Price + Length, family = "binomial", data = Cars93_sem_weight)
# Visualizar os resultados do novo modelo
summary(modelo_logistico_sem_weight)
# Atributo com menor p-value
print("O atributo com menor p-value é:")
print(which.min(summary(modelo_logistico_sem_weight)$coef[, "Pr(>|z|)"]))
# Criar um novo conjunto de dados com as características fornecidas
novos_dados <- data.frame(Price = c(17, 19, 21), Length = c(150, 170, 190))
# Fazer previsões com o modelo sem o atributo removido
predicoes <- predict(modelo_logistico_sem_atributo, newdata = novos_dados, type = "response")
# Criar um novo conjunto de dados com as características fornecidas
novos_dados <- data.frame(Price = c(17, 19, 21), Length = c(150, 170, 190))
# Fazer previsões com o modelo sem o atributo removido
predicoes <- predict(modelo_logistico_sem_weight, newdata = novos_dados, type = "response")
# Exibir as previsões
cat("Origem estimada dos veículos:")
ifelse(predicoes > 0.5, "USA", "non-USA")
df = read.csv('https://meusite.mackenzie.br/rogerio/TIC/FuelConsumptionCo2.csv',header=T)
df = read.csv('https://meusite.mackenzie.br/rogerio/TIC/FuelConsumptionCo2.csv',header=T)
df = read.csv('FuelConsumptionCo2.csv',header=T)
head(df)e
df = read.csv('FuelConsumptionCo2.csv',header=T)
head(df)
View(df)
View(df)
table(df$FUELTYPE)
# Criar o novo atributo FUELX
df$FUELX <- ifelse(df$FUELTYPE == "X", 1, 0)
# Criar o modelo logístico
modelo_logistico <- glm(FUELX ~ FUELCONSUMPTION_COMB + CO2EMISSIONS, family = binomial, data = df)
# Visualizar os resultados do modelo
summary(modelo_logistico)
# Criar o novo atributo FUELX
df$FUELX <- ifelse(df$FUELTYPE == "X", 1, 0)
# Criar o modelo logístico
modelo_logistico <- glm(FUELX ~ FUELCONSUMPTION_COMB + CO2EMISSIONS, data = df, family = "binomial")
# Visualizar os resultados do modelo
summary(modelo_logistico)
# Todos os coeficientes são significativos?
print("Todos os coeficientes são significativos?")
print(all(summary(modelo_logistico)$coef[, "Pr(>|z|)"] < 0.05))
# Predição para todos os veículos da base
predicao <- predict(modelo_logistico, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes <- ifelse(predicao > 0.5, 1, 0)
# Verificar acertos e erros do modelo
num_acertos <- sum(predicao_classes == df$FUELX)
num_erros <- sum(predicao_classes != df$FUELX)
percentual_acerto <- num_acertos / nrow(df)
print("Número de acertos:")
print(num_acertos)
print("Número de erros:")
print(num_erros)
print("Percentual de acerto:")
print(percentual_acerto)
# Predição para todos os veículos da base
predicao <- predict(modelo_logistico, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes <- ifelse(predicao > 0.5, 1, 0)
# Verificar acertos e erros do modelo
num_acertos <- sum(predicao_classes == df$FUELX)
num_erros <- sum(predicao_classes != df$FUELX)
percentual_acerto <- num_acertos / nrow(df)
print("Número de acertos:")
print(num_acertos)
print("Número de erros:")
print(num_erros)
print("Percentual de acerto:")
print(percentual_acerto)
# Predição para todos os veículos da base
predicao <- predict(modelo_logistico, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes <- ifelse(predicao > 0.5, 1, 0)
# Verificar acertos e erros do modelo
num_acertos <- sum(predicao_classes == df$FUELX)
num_erros <- sum(predicao_classes != df$FUELX)
percentual_acerto <- num_acertos / nrow(df)
print("Número de acertos:")
print(num_acertos)
print("Número de erros:")
print(num_erros)
print("Percentual de acerto:")
print(percentual_acerto)
# Estimar a probabilidade (chance logística)
fuel_comb <- 9
co2_emissions <- 180
prob <- predict(modelo_logistico, newdata = data.frame(FUELCONSUMPTION_COMB = fuel_comb, CO2EMISSIONS = co2_emissions), type = "response")
print("A chance logística de um veículo com FUELCONSUMPTION_COMB = 9 e CO2EMISSIONS = 180 ser um veículo de gasolina especial 'X' é:")
print(prob)
# Adicionar ENGINESIZE e CYLINDERS ao modelo
modelo_logistico_completo <- glm(FUELX ~ FUELCONSUMPTION_COMB + CO2EMISSIONS + ENGINESIZE + CYLINDERS, data = df, family = "binomial")
# Predição para todos os veículos da base com o modelo completo
predicao_completa <- predict(modelo_logistico_completo, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes_completa <- ifelse(predicao_completa > 0.5, 1, 0)
# Verificar acertos e erros do modelo completo
num_acertos_completo <- sum(predicao_classes_completa == df$FUELX)
percentual_acerto_completo <- num_acertos_completo / nrow(df)
print("Percentual de acerto com o modelo completo:")
print(percentual_acerto_completo)
library(MASS)
help("biopsy")
bio = na.omit(biopsy[,-c(1)]) # 1 = ID
bio$class = as.numeric(bio$class) - 1
head(bio)
View(bio)
View(bio)
# Carregar o pacote necessario
library(MASS)
# Remover linhas com valores ausentes e a primeira coluna (ID)
bio <- na.omit(biopsy[, -1])
# Converter a variável de classe para numérica (0 para benigno, 1 para maligno)
bio$class <- as.numeric(bio$class) - 1
# Implementar o modelo logístico
modelo_logistico <- glm(class ~ ., data = bio, family = "binomial")
# Obter a predição do modelo
predicao <- predict(modelo_logistico, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes <- ifelse(predicao > 0.5, 1, 0)
# Verificar acertos e erros do modelo
num_acertos <- sum(predicao_classes == bio$class)
num_erros <- sum(predicao_classes != bio$class)
percentual_acerto <- num_acertos / nrow(bio)
# Exibir o número de acertos, erros e percentual de acerto
print("Número de acertos:")
print(num_acertos)
print("Número de erros:")
print(num_erros)
print("Percentual de acerto:")
print(percentual_acerto)
# Carregar o pacote necessario
library(glmnet)
install.packages("glmnet")
# Carregar o pacote necessario
library(glmnet)
# Separar os dados em conjunto de treinamento e teste
set.seed(123) # Definir semente para reproducibilidade
indices_treino <- sample(1:nrow(bio), 0.7 * nrow(bio)) # 70% dos dados para treinamento
dados_treino <- bio[indices_treino, ]
dados_teste <- bio[-indices_treino, ]
# Criar o modelo logístico
modelo_logistico <- glm(class ~ ., data = dados_treino, family = "binomial")
# Fazer predição com o conjunto de teste
predicao <- predict(modelo_logistico, newdata = dados_teste, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes <- ifelse(predicao > 0.5, "malignant", "benign")
# Comparar os valores da predição com os valores reais da base
resultado <- data.frame(Real = dados_teste$class, Predicao = predicao_classes)
# Verificar acertos e erros do modelo
num_acertos <- sum(resultado$Real == resultado$Predicao)
num_erros <- sum(resultado$Real != resultado$Predicao)
percentual_acerto <- num_acertos / nrow(resultado)
# Imprimir resultados
print("Número de acertos:")
print(num_acertos)
print("Número de erros:")
print(num_erros)
print("Percentual de acerto:")
print(percentual_acerto)
# Carregar o pacote necessario
library(glmnet)
# Separar os dados em conjunto de treinamento e teste
set.seed(123) # Definir semente para reproducibilidade
indices_treino <- sample(1:nrow(bio), 0.7 * nrow(bio)) # 70% dos dados para treinamento
dados_treino <- bio[indices_treino, ]
dados_teste <- bio[-indices_treino, ]
# Criar o modelo logístico
modelo_logistico <- glm(class ~ ., data = dados_treino, family = "binomial")
# Fazer predição com o conjunto de teste
predicao <- predict(modelo_logistico, newdata = dados_teste, type = "response")
# Converter a probabilidade em classes (0 ou 1)
predicao_classes <- ifelse(predicao > 0.5, "malignant", "benign")
# Comparar os valores da predição com os valores reais da base
resultado <- data.frame(Real = dados_teste$class, Predicao = predicao_classes)
# Verificar acertos e erros do modelo
num_acertos <- sum(resultado$Real == resultado$Predicao)
num_erros <- sum(resultado$Real != resultado$Predicao)
percentual_acerto <- num_acertos / nrow(resultado)
# Imprimir resultados
print("Número de acertos:")
print(num_acertos)
print("Número de erros:")
print(num_erros)
print("Percentual de acerto:")
print(percentual_acerto)
install.packages(  |......                                             |  12% [setup]
install.packages(glmnet)
install.packages('glmnet')
